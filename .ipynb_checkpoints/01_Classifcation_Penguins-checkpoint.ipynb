{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/gdd-logo.png width=300px align=right>\n",
    "\n",
    "# Classification\n",
    "\n",
    "In this notebook, we shall classify penguins species based on bodily measurements using the scikit-learn API. \n",
    "\n",
    "We shall first introduce the dataset and the Scikit-Learn library. Afterwards we will cover the following aspects:\n",
    "\n",
    "- [Loading in the data](#loading-in-the-data)    \n",
    "    - [<mark>Exploring the dataset</mark>](#exploring-the-dataset) \n",
    "    - [Visualizing the dataset](#visualising-the-dataset)  \n",
    "- [Preparing the data for sklearn](#preparing)\n",
    "    - [Splitting the dataset](#train-test-split)\n",
    "- [Model creation & evaluation](#model)\n",
    "    - [Training and evaluating a Scikit-Learn model](#steps)\n",
    "    - [Visualzing the model](#vis)\n",
    "    - [<mark>Choosing a different model</mark>](#choosing-models)  \n",
    "\n",
    "![](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "The data was collected and made available by Dr. Kristen Gorman and the Palmer Station, Antartica LTER. Their goal was to provide a great dataset for data exploration, visualisation and - in this case - a demonstration of the scikit-learn API. \n",
    "\n",
    "The data set contains measurements for different species of penguins living at the Palmer station:\n",
    "\n",
    "|Field|Description|\n",
    "|:---|:---|\n",
    "|species|The species of the penguin: Adelie, Chinstrap or Gentoo|\n",
    "|island|The island on which the penguin was spotted|\n",
    "|bill_length_mm|The length of the penguin's bill in mm|\n",
    "|bill_depth_mm|The depth of the penguin's bill in mm|\n",
    "|flipper_length_mm|The length of the penguin's flipper in mm|\n",
    "|body_mass_g|The weight of the penguin in grams|\n",
    "|sex|The gender of the penguin - Female or Male|\n",
    "\n",
    "<img src=\"images/02_Classification_Penguins/culmen_depth.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "Scikit-learn is *the* library for machine learning in Python. You could consider it the swiss army knife of machine learning. A wide variety of machine learning models are implemented by the community and core developers, with a consistent API. Once you master this API, it's easy to apply a wide variety of machine learning algorithms, and you have a handy tool to help you out with preprocessing, model evaluation and model selection. \n",
    "\n",
    "#### Why scikit-learn?\n",
    "- Many available machine learning models\n",
    "- Models are implemented by an expert team and checked by a large community\n",
    "- Covers most machine-learning tasks\n",
    "- Commitment to documentation, consistency and usability\n",
    "- Designed to work with other key Python libraries (NumPy, Pandas etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'loading-in-the-data'></a>\n",
    "## 1. Loading in the data\n",
    "\n",
    "There are many places your data can originate from. Maybe you want to load it from a Excel file you have stored locally on your system, maybe you have a .csv file stored online somewhere. Scikit-learn comes with various standard datasets that can be used for practice, that can be loaded if you have scikit-learn installed on your system. \n",
    "\n",
    "Our dataset will be loaded in as a Pandas dataframe and can be used as such. Pandas is a powerful library for data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>195.0</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "6  Adelie  Torgersen            38.9           17.8              181.0   \n",
       "7  Adelie  Torgersen            39.2           19.6              195.0   \n",
       "8  Adelie  Torgersen            34.1           18.1              193.0   \n",
       "9  Adelie  Torgersen            42.0           20.2              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  \n",
       "6       3625.0  Female  \n",
       "7       4675.0    Male  \n",
       "8       3475.0     NaN  \n",
       "9       4250.0     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv('data/penguins.csv')\n",
    "penguins.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'exploring-the-dataset'></a>\n",
    "## <mark> Exercise: Exploring the dataset </mark>\n",
    "\n",
    "Below are some typical things you may want to check as part of your initial investigation of the dataset.\n",
    "\n",
    "1. How many rows and columns are present in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which data types are used by each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How many species are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How many penguins are there for each species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'visualising-the-dataset'></a>\n",
    "## Visualising the dataset \n",
    "\n",
    "To understand the dataset better it can be useful to create some visualisations.\n",
    "\n",
    "Below is a  histogram of the penguin's flipper lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x='flipper_length_mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use visualisations to examine how different the data is for the different species.\n",
    "\n",
    "For example, here is a histogram of flipper lengths *for the different species*. Would you be able to separate the species based on this measurement alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x='flipper_length_mm', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the relationship between two variables.\n",
    "\n",
    "Below is a scatter plot of flipper length vs. body mass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be easier to distinguish different species when we look at more than one variable.\n",
    "\n",
    "Here is a a scatter plot of flipper length vs. body mass *for the different species*. Would you be able to separate the species based on the relationship between these measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn also allows us to see this information for each numeric feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=penguins, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'preparing'></a>\n",
    "## 2. Preparing the data for scikit-learn\n",
    "\n",
    "The first thing we might notice here is that there are some data point entries that have no value - the value simply says `NaN`. This means this information is missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    penguins\n",
    "    .loc[penguins.isnull().any(axis=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, that also means the information cannot be used as is to create a machine learning model with scikit-learn. We must find a way to deal with the missing values. \n",
    "\n",
    "There are multiple strategies for dealing with missing data. For example, you could replace a missing values with the mean of the column. E.g. if for a particular penguin the value for body mass is missing, you could replace the NaN with the mean recorded body mass of all penguins. \n",
    "\n",
    "Scikit-learn even provides us with a great interface to apply such transformations. For the moment, however, we simply choose to discard all the incomplete data points with pandas `.dropna()` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_cleaned = penguins.dropna()\n",
    "penguins_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second of all, we notice that we have more information than the penguin measurements _bill length, bill depth, flipper length_ and _body mass_.\n",
    "\n",
    "Although we could incorporate this extra information (sex of the penguin and the island where the penguin was spotted), this requires some extra preprocessing outside of the scope of this notebook. We choose to focus on our four discussed features first.\n",
    "\n",
    "We then use our knowledge of Pandas to create our feature matrix $X$ and target vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "X = penguins_cleaned.loc[:, feature_columns]\n",
    "y = penguins_cleaned.loc[:, 'species']\n",
    "\n",
    "print(f'The shape of feature matrix X is: {X.shape}')\n",
    "print(f'The shape of target vector y is: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix columns are also known as the predictive variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target,/label vector is known as the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature matrix $X$ consists of $n$ samples with $m$ features - in this case $n=333$ and $m=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the feature matrix $X$ corresponds to a value in the target vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will then attempt to learn a relationship that can map a row in $X$ to the corresponding value in $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'train-test-split'></a>\n",
    "### Splitting the dataset\n",
    "An important goal of machine learning is to create a model that does not only do well on the data that it has already seen, but will also perform well under new circumstances on data that is has not seen before. We call this _generalization_. \n",
    "\n",
    "Imagine this: Penguin A is a gentoo (bill length of 33, bill depth of of 16, flipper length of 180 and body mass of 3500 grams). \n",
    "\n",
    "<img src=\"images/02_Classification_Penguins/gentoo.jpg\" width=\"300\">\n",
    "\n",
    "Penguin A was presented during the training of our model; that means, penguin A was one of the examples that the algorithm used to create an understanding of what a gentoo looks like and how you can distinguish it from a chinstrap or adÃ©lie. \n",
    "\n",
    "If we want to know how well our model does, asking the model to classify our penguin A does not give us a lot of information. \n",
    "\n",
    "Even if the model is correct, do we know whether it has really truly learned the relationship between the features and the targets (ie. flipper length of >X is always species Y), or has it simply memorized the original data and does it recognise penguin A from the training phase? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why we want to separate our dataset into two parts:\n",
    "* The _training_ set: this is the data (features and targets) that will guide the learning process. \n",
    "* The _test_ set: this is the data (features and targets) that we will use to _evaluate_ how well our model has learned. \n",
    "\n",
    "<img src=\"images/02_Classification_Penguins/train-test.png\" width=\"600\">\n",
    "\n",
    "Scikit-learn's `train_test_split` function allows us to split the data in a train- and testset. By default, the test set size is set to 25% and the data is shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "print(f'The size of our feature matrix for the train set is: {X_train.shape}')\n",
    "print(f'The size of our target vector for the train set is: {y_train.shape}')\n",
    "\n",
    "print(f'\\nThe size of our feature matrix for the test set is: {X_test.shape}')\n",
    "print(f'The size of our target vector for the test set is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our data is in fact shuffled: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'model'></a>\n",
    "## 3. Model creation and evaluation\n",
    "\n",
    "Now we're ready to create our machine learning model! \n",
    "\n",
    "Scikit-learn has a rich collection of algorithms readily available. Depending on the case you are working on, scikit-learn most likely has a model that will suit your purposes. \n",
    "\n",
    "<a id = 'steps'></a>\n",
    "## Training a Scikit-Learn model\n",
    "\n",
    "Below are the steps for training a model using the Scikit-Learn API \n",
    "1. Choosing a model class and importing that model \n",
    "2. Choosing the model hyperparameters by instantiating this class with desired values.\n",
    "3. Training the model to the preprocessed train data by calling the `fit()` method of the model instance.\n",
    "4. Evaluating model's performance using available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: import the chosen algorithm \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/02_Classification_Penguins/tree.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: instantiate the model with the chosen hyperparameters\n",
    "model = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: train the model with the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained a model that can be used to make predictions on new data. Remember our test set? That's new, unseen data to the model that we can now create predictions on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare these predictions against our original data to see how well our model does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we don't have to do that comparison ourselves. Scikit-learn has made many implementations of possible metrics readily available, such as accuracy. \n",
    "\n",
    "$\\text{accuracy} = \\frac{correct}{total}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! \n",
    "\n",
    "Alternatively you can use the `.score()` method. On a Decision Tree this will return the accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'vis'></a>\n",
    "## Model Visualisation\n",
    "\n",
    "One of the advantages of decision trees over some of the other available models, is that decision trees are relatively easy to interpret. By visualising the tree-like structure of the decision tree, we can understand why the model classifies samples the way it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "\n",
    "plot_tree(model, \n",
    "          ax=ax, \n",
    "          feature_names = feature_columns, \n",
    "          class_names = y.unique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'choosing-models'></a>\n",
    "## <mark>Choosing a different model </mark>\n",
    "\n",
    "What happens when we're interested in a model other than the decision tree? \n",
    "\n",
    "That's actually really easy. You simply replace the chosen model with another and the rest of the pipeline can stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# Uncomment the model that you want to try\n",
    "model = DecisionTreeClassifier()\n",
    "# model = RandomForestClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "# model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Model accuracy: {model.score(X_test, y_test)}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Scikit-learn is an excellent, resourceful tool for machine learning in Python. We've seen how we can split a dataset with `train_test_split` into a train and test set, create and train a model, use the trained model to create predictions, and how to use the tools from `sklearn.metrics` to evaluate how good the model is. \n",
    "![](images/02_Classification_Penguins/palmer-penguins.png) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
